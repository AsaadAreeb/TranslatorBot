{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "GYN63T4XBoif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "aAZF4wvxZDeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([,.!?])\", r\" \\1 \", s)\n",
        "    s = re.sub(r\"[^a-zA-Z,.!?]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s"
      ],
      "metadata": {
        "id": "ok8dn5wGBdv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('/content/drive/MyDrive/Seq2Seq_Translation/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "kAx9p54nBrgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "Nfo-GD3PW0XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQFPK2O-W2lW",
        "outputId": "9af2aa54-d170-49d9-aea3-f470e8e0b5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10486 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4328\n",
            "eng 2797\n",
            "['elle passe a la tele ce soir .', 'she is appearing on tv tonight .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "kgRakqE8XHSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "nP1gq2vLXKM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "ZSVeFD-kXSY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader"
      ],
      "metadata": {
        "id": "tUGPjCS6XZkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "CV1qC5LEXcEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "WxM9tKMxXd0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "DEx00R_dXhLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "wrgyJOwPXmKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ],
      "metadata": {
        "id": "VgydAjAGXo4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "fVOouvc1Xqb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfetkVL_YIyj",
        "outputId": "25f1a661-e796-414a-8e77-974820ee3aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10486 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4328\n",
            "eng 2797\n",
            "0m 37s (- 9m 16s) (5 6%) 1.5113\n",
            "1m 13s (- 8m 31s) (10 12%) 0.6882\n",
            "1m 48s (- 7m 50s) (15 18%) 0.3736\n",
            "2m 24s (- 7m 13s) (20 25%) 0.2126\n",
            "2m 59s (- 6m 34s) (25 31%) 0.1315\n",
            "3m 52s (- 6m 27s) (30 37%) 0.0896\n",
            "4m 33s (- 5m 52s) (35 43%) 0.0676\n",
            "5m 11s (- 5m 11s) (40 50%) 0.0553\n",
            "5m 47s (- 4m 30s) (45 56%) 0.0462\n",
            "6m 22s (- 3m 49s) (50 62%) 0.0416\n",
            "6m 57s (- 3m 9s) (55 68%) 0.0378\n",
            "7m 35s (- 2m 31s) (60 75%) 0.0350\n",
            "8m 11s (- 1m 53s) (65 81%) 0.0333\n",
            "8m 46s (- 1m 15s) (70 87%) 0.0318\n",
            "9m 22s (- 0m 37s) (75 93%) 0.0303\n",
            "9m 56s (- 0m 0s) (80 100%) 0.0288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1T3BerFYM9J",
        "outputId": "2db0a87a-8a53-457b-9e38-e451e57ecf35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> vous etes grossieres .\n",
            "= you re rude .\n",
            "< you are rude to talk . <EOS>\n",
            "\n",
            "> t es un gros nounours .\n",
            "= you re a big softy .\n",
            "< you re a big fan , too . <EOS>\n",
            "\n",
            "> je n ai pas vraiment faim .\n",
            "= i m not really hungry .\n",
            "< i m not really hungry . <EOS>\n",
            "\n",
            "> je vais juste faire une promenade .\n",
            "= i am just going for a walk .\n",
            "< i am just going for a walk . <EOS>\n",
            "\n",
            "> il est nerveux d aller en amerique .\n",
            "= he is anxious to go to america .\n",
            "< he is anxious to go to america . <EOS>\n",
            "\n",
            "> il est le meilleur ami de mon mari .\n",
            "= he is my husband s best friend .\n",
            "< he is my husband s best friend . <EOS>\n",
            "\n",
            "> je n ai pas faim du tout .\n",
            "= i m not hungry at all .\n",
            "< i m not even a little hungry . <EOS>\n",
            "\n",
            "> tu es un de ces dragueurs !\n",
            "= you re such a flirt .\n",
            "< you re such a flirt . <EOS>\n",
            "\n",
            "> tu es une de ces menteuses !\n",
            "= you are such a liar !\n",
            "< you are such a liar ! <EOS>\n",
            "\n",
            "> vous etes tous des racistes .\n",
            "= you re all racists .\n",
            "< you re all racists . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    input_words = input_sentence.split(' ') + ['<EOS>']\n",
        "    ax.set_xticks(range(len(input_words)))\n",
        "    ax.set_yticks(range(len(output_words)))\n",
        "\n",
        "    ax.set_xticklabels(input_words, rotation=90)\n",
        "    ax.set_yticklabels(output_words)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
        "\n",
        "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
        "\n",
        "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
        "\n",
        "evaluateAndShowAttention('je suis reellement fiere de vous')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7HE9_1cYPcM",
        "outputId": "eb86773f-8453-4acc-fd50-56ff08e74377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = il n est pas aussi grand que son pere\n",
            "output = he is not as tall as his father . <EOS>\n",
            "input = je suis trop fatigue pour conduire\n",
            "output = i m too tired to drive . <EOS>\n",
            "input = je suis desole si c est une question idiote\n",
            "output = i m sorry so a night problem . <EOS>\n",
            "input = je suis reellement fiere de vous\n",
            "output = i m really proud of you . <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises\n",
        "- Try with a different dataset\n",
        "\n",
        "    - Another language pair\n",
        "\n",
        "    - Human → Machine (e.g. IOT commands)\n",
        "\n",
        "    - Chat → Response\n",
        "\n",
        "    - Question → Answer\n",
        "\n",
        "- Replace the embeddings with pretrained word embeddings such as word2vec or GloVe\n",
        "\n",
        "- Try with more layers, more hidden units, and more sentences. Compare the training time and results.\n",
        "\n",
        "- If you use a translation file where pairs have two of the same phrase (I am test \\t I am test), you can use this as an autoencoder. Try this:\n",
        "\n",
        "    - Train as an autoencoder\n",
        "\n",
        "    - Save only the Encoder network\n",
        "\n",
        "    - Train a new Decoder for translation from there"
      ],
      "metadata": {
        "id": "RdLbw_lJZ7_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MIN_LENGTH = 3\n",
        "# MAX_LENGTH = 25\n",
        "\n",
        "# def filterPairs(pairs):\n",
        "#     filtered_pairs = []\n",
        "#     for pair in pairs:\n",
        "#         if len(pair[0]) >= MIN_LENGTH and len(pair[0]) <= MAX_LENGTH \\\n",
        "#             and len(pair[1]) >= MIN_LENGTH and len(pair[1]) <= MAX_LENGTH:\n",
        "#                 filtered_pairs.append(pair)\n",
        "#     return filtered_pairs"
      ],
      "metadata": {
        "id": "AF15bZSdjmiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOT DOING THIS, BUT YOU CAN TRY\n",
        "# MAX_LENGTH = 10\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "# def filterPair(p):\n",
        "#     return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
        "\n",
        "# def filterPairs(pairs):\n",
        "#     return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "HAY-u6CGbCLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = ['I am sick.', 'میں بیمار ہوں۔']\n",
        "# a = [ai.lower() for ai in a]\n",
        "# print(a)"
      ],
      "metadata": {
        "id": "bu-mWfqsc2Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filterPair(a)"
      ],
      "metadata": {
        "id": "duanVqn8erKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a[0], a[1]"
      ],
      "metadata": {
        "id": "Kx_Mxa4ZdpdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(a[0].split(' ')) < MAX_LENGTH, len(a[1].split(' ')) < MAX_LENGTH, a[1].startswith(eng_prefixes)"
      ],
      "metadata": {
        "id": "radJiYKSeTJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def prepareData(lang1, lang2, reverse=False):\n",
        "#     input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "#     print(\"Read %d sentence pairs\" % len(pairs))\n",
        "\n",
        "#     pairs = filterPairs(pairs)\n",
        "#     # print(pairs)\n",
        "#     print(\"Filtered to %d pairs\" % len(pairs))\n",
        "\n",
        "#     print(\"Indexing words...\")\n",
        "#     for pair in pairs:\n",
        "#         input_lang.addSentence(pair[0])\n",
        "#         output_lang.addSentence(pair[1])\n",
        "\n",
        "#     print('Indexed %d words in input language, %d words in output' % (input_lang.n_words, output_lang.n_words))\n",
        "#     return input_lang, output_lang, pairs\n",
        "\n",
        "# input_lang, output_lang, pairs = prepareData('eng', 'fra', False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwuU1GvkeabF",
        "outputId": "0bbf671f-b039-46ef-932d-5e94d7b842f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Filtered to 25717 pairs\n",
            "Indexing words...\n",
            "Indexed 4346 words in input language, 7002 words in output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDtAlfRzmyM7",
        "outputId": "80139976-0494-4292-bccd-eed390c8627d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['it is too expensive .', 'c est trop cher .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MIN_COUNT = 5\n",
        "\n",
        "# input_lang.trim(MIN_COUNT)\n",
        "# output_lang.trim(MIN_COUNT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uaDq0UxpTI3",
        "outputId": "228e8083-1d45-4fa3-e03a-d0ec0724cf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keep_words 1530 / 4343 = 0.3523\n",
            "keep_words 1718 / 6999 = 0.2455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keep_pairs = []\n",
        "\n",
        "# for pair in pairs:\n",
        "#     input_sentence = pair[0]\n",
        "#     output_sentence = pair[1]\n",
        "#     keep_input = True\n",
        "#     keep_output = True\n",
        "\n",
        "#     for word in input_sentence.split(' '):\n",
        "#         if word not in input_lang.word2index:\n",
        "#             keep_input = False\n",
        "#             break\n",
        "\n",
        "#     for word in output_sentence.split(' '):\n",
        "#         if word not in output_lang.word2index:\n",
        "#             keep_output = False\n",
        "#             break\n",
        "\n",
        "#     # Remove if pair doesn't match input and output conditions\n",
        "#     if keep_input and keep_output:\n",
        "#         keep_pairs.append(pair)\n",
        "\n",
        "# print(\"Trimmed from %d pairs to %d, %.4f of total\" % (len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
        "# pairs = keep_pairs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAC4KoVspf20",
        "outputId": "4d0db880-b643-4cd8-ef07-e324f4b9c0b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trimmed from 25717 pairs to 15909, 0.6186 of total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Return a list of indexes, one for each word in the sentence, plus EOS\n",
        "# def indexesFromSentence(lang, sentence):\n",
        "#     return [lang.word2index[word] for word in sentence.split(' ')] + [EOS_token]"
      ],
      "metadata": {
        "id": "dVhAZm3qqnxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Pad a with the PAD symbol\n",
        "# def padSeq(seq, max_length):\n",
        "#     seq += [PAD_token for i in range(max_length - len(seq))]\n",
        "#     return seq"
      ],
      "metadata": {
        "id": "AJPHFvJt6ZiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def random_batch(batch_size):\n",
        "#     input_seqs = []\n",
        "#     target_seqs = []\n",
        "\n",
        "#     # Choose random pairs\n",
        "#     for i in range(batch_size):\n",
        "#         pair = random.choice(pairs)\n",
        "#         input_seqs.append(indexesFromSentence(input_lang, pair[0]))\n",
        "#         target_seqs.append(indexesFromSentence(output_lang, pair[1]))\n",
        "\n",
        "#     # Zip into pairs, sort by length (descending), unzip\n",
        "#     seq_pairs = sorted(zip(input_seqs, target_seqs), key=lambda p: len(p[0]), reverse=True)\n",
        "#     input_seqs, target_seqs = zip(*seq_pairs)\n",
        "\n",
        "#     # For input and target sequences, get array of lengths and pad with 0s to max length\n",
        "#     input_lengths = [len(s) for s in input_seqs]\n",
        "#     input_padded = [padSeq(s, max(input_lengths)) for s in input_seqs]\n",
        "#     target_lengths = [len(s) for s in target_seqs]\n",
        "#     target_padded = [padSeq(s, max(target_lengths)) for s in target_seqs]\n",
        "\n",
        "#     # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
        "#     input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
        "#     target_var = Variable(torch.LongTensor(target_padded)).transpose(0, 1)\n",
        "\n",
        "#     if USE_CUDA:\n",
        "#         input_var = input_var.cuda()\n",
        "#         target_var = target_var.cuda()\n",
        "\n",
        "#     return input_var, input_lengths, target_var, target_lengths"
      ],
      "metadata": {
        "id": "ixk-_aEf6sIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random_batch(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5qoyiCf-zNN",
        "outputId": "71ae6901-b530-4f18-f6e1-516945ba9c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 12,  12],\n",
              "         [102, 211],\n",
              "         [186,  91],\n",
              "         [  3, 602],\n",
              "         [  4,   4],\n",
              "         [  2,   2]]),\n",
              " [6, 6],\n",
              " tensor([[112,  20],\n",
              "         [209, 337],\n",
              "         [325, 108],\n",
              "         [196, 849],\n",
              "         [ 58,  14],\n",
              "         [245,   2],\n",
              "         [ 14,   0],\n",
              "         [  2,   0]]),\n",
              " [8, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class EncoderRNN(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
        "#         super(EncoderRNN, self).__init__()\n",
        "\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.n_layers = n_layers\n",
        "#         self.dropout = dropout\n",
        "\n",
        "#         self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "#         self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
        "\n",
        "#     def forward(self, input_seqs, input_lengths, hidden=None):\n",
        "#         # Note: we run this all at once (over multiple batches of multiple sequences)\n",
        "#         embedded = self.embedding(input_seqs)\n",
        "#         packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "#         outputs, hidden = self.gru(packed, hidden)\n",
        "#         outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
        "#         outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
        "#         return outputs, hidden"
      ],
      "metadata": {
        "id": "brtVzp4G-2tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Attn(nn.Module):\n",
        "#     def __init__(self, method, hidden_size):\n",
        "#         super(Attn, self).__init__()\n",
        "#         self.method = method\n",
        "#         if self.method not in ['dot', 'general', 'concat']:\n",
        "#             raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "#         self.hidden_size = hidden_size\n",
        "#         if self.method == 'general':\n",
        "#             self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "#         elif self.method == 'concat':\n",
        "#             self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "#             self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "#     def dot_score(self, hidden, encoder_output):\n",
        "#         return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "#     def general_score(self, hidden, encoder_output):\n",
        "#         energy = self.attn(encoder_output)\n",
        "#         return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "#     def concat_score(self, hidden, encoder_output):\n",
        "#         energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "#         return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "#     def forward(self, hidden, encoder_outputs):\n",
        "#         # Calculate the attention weights (energies) based on the given method\n",
        "#         if self.method == 'general':\n",
        "#             attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "#         elif self.method == 'concat':\n",
        "#             attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "#         elif self.method == 'dot':\n",
        "#             attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "#         # Transpose max_length and batch_size dimensions\n",
        "#         attn_energies = attn_energies.t()\n",
        "\n",
        "#         # Return the softmax normalized probability scores (with added dimension)\n",
        "#         return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ],
      "metadata": {
        "id": "Nslk_IHrEpao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class BahdanauAttnDecoderRNN(nn.Module):\n",
        "#     def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
        "#         super(BahdanauAttnDecoderRNN, self).__init__()\n",
        "\n",
        "#         # Define parameters\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.output_size = output_size\n",
        "#         self.n_layers = n_layers\n",
        "#         self.dropout_p = dropout_p\n",
        "#         self.max_length = max_length\n",
        "\n",
        "#         # Define layers\n",
        "#         self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "#         self.dropout = nn.Dropout(dropout_p)\n",
        "#         self.attn = Attn('concat', hidden_size)\n",
        "#         self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
        "#         self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#     def forward(self, word_input, last_hidden, encoder_outputs):\n",
        "#         # Note: we run this one step at a time\n",
        "#         # TODO: FIX BATCHING\n",
        "\n",
        "#         # Get the embedding of the current input word (last output word)\n",
        "#         word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
        "#         word_embedded = self.dropout(word_embedded)\n",
        "\n",
        "#         # Calculate attention weights and apply to encoder outputs\n",
        "#         attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
        "#         context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
        "#         context = context.transpose(0, 1) # 1 x B x N\n",
        "\n",
        "#         # Combine embedded input word and attended context, run through RNN\n",
        "#         rnn_input = torch.cat((word_embedded, context), 2)\n",
        "#         output, hidden = self.gru(rnn_input, last_hidden)\n",
        "\n",
        "#         # Final output layer\n",
        "#         output = output.squeeze(0) # B x N\n",
        "#         output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
        "\n",
        "#         # Return final output, hidden state, and attention weights (for visualization)\n",
        "#         return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "Xk4l7h-gM1aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class LuongAttnDecoderRNN(nn.Module):\n",
        "#     def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "#         super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "#         # Keep for reference\n",
        "#         self.attn_model = attn_model\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.output_size = output_size\n",
        "#         self.n_layers = n_layers\n",
        "#         self.dropout = dropout\n",
        "\n",
        "#         # Define layers\n",
        "#         self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "#         self.embedding_dropout = nn.Dropout(dropout)\n",
        "#         self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
        "#         self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "#         self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#         # Choose attention model\n",
        "#         if attn_model != 'none':\n",
        "#             self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "#     def forward(self, input_seq, last_hidden, encoder_outputs):\n",
        "#         # Note: we run this one step at a time\n",
        "\n",
        "#         # Get the embedding of the current input word (last output word)\n",
        "#         batch_size = input_seq.size(0)\n",
        "#         embedded = self.embedding(input_seq)\n",
        "#         embedded = self.embedding_dropout(embedded)\n",
        "#         embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n",
        "\n",
        "#         # Get current hidden state from input word and last hidden state\n",
        "#         rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "\n",
        "#         # Calculate attention from current RNN state and all encoder outputs;\n",
        "#         # apply to encoder outputs to get weighted average\n",
        "#         attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "#         context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n",
        "\n",
        "#         # Attentional vector using the RNN hidden state and context vector\n",
        "#         # concatenated together (Luong eq. 5)\n",
        "#         rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
        "#         context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
        "#         concat_input = torch.cat((rnn_output, context), 1)\n",
        "#         concat_output = F.tanh(self.concat(concat_input))\n",
        "\n",
        "#         # Finally predict next token (Luong eq. 6, without softmax)\n",
        "#         output = self.out(concat_output)\n",
        "\n",
        "#         # Return final output, hidden state, and attention weights (for visualization)\n",
        "#         return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "xBeqypF5J36v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# small_batch_size = 3\n",
        "# input_batches, input_lengths, target_batches, target_lengths = random_batch(small_batch_size)\n",
        "\n",
        "# print('input_batches', input_batches.size()) # (max_len x batch_size)\n",
        "# print('target_batches', target_batches.size()) # (max_len x batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W2bbEw3M5bq",
        "outputId": "a854ffe2-4d72-45b1-8426-28a842ee496b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_batches torch.Size([7, 3])\n",
            "target_batches torch.Size([8, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_batches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zphOvbjrNWvG",
        "outputId": "60907dcd-af17-45ab-b498-2a0aed2729e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  12,  146,   22],\n",
              "        [1037,  191,   70],\n",
              "        [ 186,  872,  324],\n",
              "        [ 203,  186,  272],\n",
              "        [1155,   94,    4],\n",
              "        [   4,    4,    2],\n",
              "        [   2,    2,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# small_hidden_size = 8\n",
        "# small_n_layers = 2\n",
        "\n",
        "# encoder_test = EncoderRNN(input_lang.n_words, small_hidden_size, small_n_layers)\n",
        "# decoder_test = LuongAttnDecoderRNN('general', small_hidden_size, output_lang.n_words, small_n_layers)\n",
        "\n",
        "# if USE_CUDA:\n",
        "#     encoder_test.cuda()\n",
        "#     decoder_test.cuda()"
      ],
      "metadata": {
        "id": "6QASgkBlM7rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder_outputs, encoder_hidden = encoder_test(input_batches, input_lengths, None)\n",
        "\n",
        "# print('encoder_outputs', encoder_outputs.size()) # max_len x batch_size x hidden_size\n",
        "# print('encoder_hidden', encoder_hidden.size()) # n_layers * 2 x batch_size x hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9dAYyD0NAU-",
        "outputId": "65bb53c5-010b-4e6a-c159-9f0ff69c0c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_outputs torch.Size([7, 3, 8])\n",
            "encoder_hidden torch.Size([4, 3, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max_target_length = max(target_lengths)\n",
        "\n",
        "# # Prepare decoder input and outputs\n",
        "# decoder_input = Variable(torch.LongTensor([SOS_token] * small_batch_size))\n",
        "# decoder_hidden = encoder_hidden[:decoder_test.n_layers] # Use last (forward) hidden state from encoder\n",
        "# all_decoder_outputs = Variable(torch.zeros(max_target_length, small_batch_size, decoder_test.output_size))\n",
        "\n",
        "# if USE_CUDA:\n",
        "#     all_decoder_outputs = all_decoder_outputs.cuda()\n",
        "#     decoder_input = decoder_input.cuda()\n",
        "\n",
        "# # Run through decoder one time step at a time\n",
        "# for t in range(max_target_length):\n",
        "#     decoder_output, decoder_hidden, decoder_attn = decoder_test(\n",
        "#         decoder_input, decoder_hidden, encoder_outputs\n",
        "#     )\n",
        "#     all_decoder_outputs[t] = decoder_output # Store this step's outputs\n",
        "#     decoder_input = target_batches[t] # Next input is current target\n",
        "\n",
        "# # Test masked cross entropy loss\n",
        "# loss = F.cross_entropy(\n",
        "#     all_decoder_outputs.transpose(0, 1).contiguous(),\n",
        "#     target_batches.transpose(0, 1).contiguous(),\n",
        "#     target_lengths\n",
        "# )\n",
        "# print('loss', loss.data[0])"
      ],
      "metadata": {
        "id": "xwoTczK6NJA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q2vyUA8cQqcM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}